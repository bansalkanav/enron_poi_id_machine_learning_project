{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the best classifier for the POI in the Enron case\n",
    "\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Loading the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n",
      "Number of features: 21\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "c = 0\n",
    "for key in data_dict:\n",
    "    if c < 1:\n",
    "        for feature in data_dict[key]:\n",
    "            all_features.append(feature)\n",
    "        c += 1\n",
    "print \"Features: \\n{}\".format(all_features)\n",
    "print \"Number of features: {}\".format(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Removal of \"TOTAL\" and \"THE TRAVEL AGENCY IN THE PARK\"**\n",
    "\n",
    "\"TOTAL\"'s removal was discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop(\"TOTAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed from looking at the dictionary that \"THE TRAVEL AGENCY IN THE PARK\" isn't a person so I remove it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing what other people has done to treat data on the Enron case, I found out that LOCKHART EUGENE E does not have data in it, so it is removed here, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('LOCKHART EUGENE E') # no data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixing some data points**\n",
    "\n",
    "Also from other people's work, I found out that two datapoints have errors. Here, I manually fix the data for two people whose total_payments and total_stock_value didn't add up. These values were obtained from the pdf file provided (enron61702insiderpay.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict['BELFER ROBERT']['director_fees'] = 102500\n",
    "data_dict['BELFER ROBERT']['exercised_stock_options'] = 0\n",
    "data_dict['BELFER ROBERT']['expenses'] = 3285\n",
    "data_dict['BELFER ROBERT']['restricted_stock_deferred'] = -44093\n",
    "data_dict['BELFER ROBERT']['total_payments'] = 3285\n",
    "data_dict['BELFER ROBERT']['deferred_income'] = -102500\n",
    "data_dict['BELFER ROBERT']['deferral_payments'] = 0\n",
    "data_dict['BELFER ROBERT']['restricted_stock'] = 44093\n",
    "data_dict['BELFER ROBERT']['total_stock_value'] = 0\n",
    "\n",
    "data_dict['BHATNAGAR SANJAY']['director_fees'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['exercised_stock_options'] = 15456290\n",
    "data_dict['BHATNAGAR SANJAY']['expenses'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['other'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock'] = 2604490\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock_deferred'] = -2604490\n",
    "data_dict['BHATNAGAR SANJAY']['total_payments'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['total_stock_value'] = 15456290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivation of new features, \"fraction_to_poi\", \"fraction_from_poi\"**\n",
    "\n",
    "These were discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeFraction(poi_messages, all_messages):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "    \"\"\"\n",
    "    if poi_messages != 'NaN' or all_messages != 'NaN':\n",
    "        fraction = float(poi_messages) / float(all_messages)\n",
    "    else:\n",
    "        fraction = 0\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in data_dict:\n",
    "    data_point = data_dict[name]\n",
    "    \n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction(from_poi_to_this_person, to_messages)\n",
    "    \n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "    \n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    \n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether the new features were added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "c = 0\n",
    "for key in data_dict:\n",
    "    if c < 1:\n",
    "        for feature in data_dict[key]:\n",
    "            all_features.append(feature)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to_messages',\n",
       " 'deferral_payments',\n",
       " 'expenses',\n",
       " 'poi',\n",
       " 'deferred_income',\n",
       " 'email_address',\n",
       " 'long_term_incentive',\n",
       " 'fraction_from_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'shared_receipt_with_poi',\n",
       " 'loan_advances',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'director_fees',\n",
       " 'bonus',\n",
       " 'total_stock_value',\n",
       " 'from_poi_to_this_person',\n",
       " 'from_this_person_to_poi',\n",
       " 'restricted_stock',\n",
       " 'salary',\n",
       " 'total_payments',\n",
       " 'fraction_to_poi',\n",
       " 'exercised_stock_options']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removal of Some Features**\n",
    "\n",
    "Because of the new feautures above, it only makes sense to remove the features used to come up with the new features. \"email_address\" is removed because it will not give a numeric data type that can be used to create the numpy arrays for the analysis. \"poi\" is removed for the moment because it needs to be the first element in the list as indicated in the function used to create the numpy arrays (featureFormat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_remove = [\"poi\", \"email_address\", \"from_poi_to_this_person\", \"from_this_person_to_poi\", \"from_messages\", \"to_messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_list = ['poi', 'deferral_payments', 'expenses', 'deferred_income', 'long_term_incentive', 'fraction_from_poi', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'other', 'director_fees', 'bonus', 'total_stock_value', 'restricted_stock', 'salary', 'total_payments', 'fraction_to_poi', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "features_list = [\"poi\"]\n",
    "for feature in all_features:\n",
    "    if feature not in features_remove:\n",
    "        features_list.append(feature)\n",
    "print \"features_list = {}\".format(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting features and labels from dataset for local testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a variety of classifiers\n",
    "\n",
    "Here, I explore various classifiers by looping over them and collecting scores for each classfier in a dictionary.\n",
    "\n",
    "But before this can be done, the data is split into training and testing sets. As hinted in the provided tester.py, splitting the data is done using StratifiedShuffleSplit to account for the fact that the number of one class (i.e. POI) is a lot lower than the other (non-POI). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the features to test and train, converting to numpy arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "cv = StratifiedShuffleSplit(n_splits=1000, random_state=42)\n",
    "for train_idx, test_idx in cv.split(features, labels):\n",
    "    features_train, features_test = features[train_idx], features[test_idx]\n",
    "    labels_train, labels_test = labels[train_idx], labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importing modules **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "features_train_minmax = min_max_scaler.fit_transform(features_train)\n",
    "features_test_minmax = min_max_scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Selection Using SelectKBest **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select = SelectKBest()\n",
    "select.fit(features_train_minmax, labels_train)\n",
    "features_train_minmax_skb = select.transform(features_train_minmax)\n",
    "features_test_minmax_skb = select.transform(features_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.63967964e-01,   5.89873442e+00,   5.27911024e+00,\n",
       "         2.61127433e+00,   2.34933761e+00,   7.93834480e-01,\n",
       "         5.49532138e+00,   1.97148818e-01,   1.41634132e-02,\n",
       "         1.96160845e+00,   1.11294792e+01,   1.46898644e+01,\n",
       "         6.57270161e+00,   1.11962683e+01,   2.77163445e+00,\n",
       "         8.24301644e+00,   1.37141611e+01])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.08306946e-01,   1.65631782e-02,   2.32316086e-02,\n",
       "         1.08607636e-01,   1.27843297e-01,   3.74641359e-01,\n",
       "         2.06317493e-02,   6.57793758e-01,   9.05456857e-01,\n",
       "         1.63799239e-01,   1.11679789e-03,   1.99026034e-04,\n",
       "         1.15300149e-02,   1.08049888e-03,   9.84329051e-02,\n",
       "         4.80039891e-03,   3.17064113e-04])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select.pvalues_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'deferral_payments',\n",
       " 'expenses',\n",
       " 'deferred_income',\n",
       " 'long_term_incentive',\n",
       " 'fraction_from_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'shared_receipt_with_poi',\n",
       " 'loan_advances',\n",
       " 'other',\n",
       " 'director_fees',\n",
       " 'bonus',\n",
       " 'total_stock_value',\n",
       " 'restricted_stock',\n",
       " 'salary',\n",
       " 'total_payments',\n",
       " 'fraction_to_poi',\n",
       " 'exercised_stock_options']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance = zip(features_list[1:], select.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deferral_payments', 0.26396796392070854),\n",
       " ('expenses', 5.8987344206928967),\n",
       " ('deferred_income', 5.2791102364434765),\n",
       " ('long_term_incentive', 2.611274332028505),\n",
       " ('fraction_from_poi', 2.3493376092169673),\n",
       " ('restricted_stock_deferred', 0.79383448019177838),\n",
       " ('shared_receipt_with_poi', 5.495321379933408),\n",
       " ('loan_advances', 0.19714881780250351),\n",
       " ('other', 0.014163413206360534),\n",
       " ('director_fees', 1.9616084482924003),\n",
       " ('bonus', 11.129479151071294),\n",
       " ('total_stock_value', 14.689864354826563),\n",
       " ('restricted_stock', 6.5727016131222769),\n",
       " ('salary', 11.196268305382173),\n",
       " ('total_payments', 2.7716344531988995),\n",
       " ('fraction_to_poi', 8.2430164382598381),\n",
       " ('exercised_stock_options', 13.714161147390753)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total_stock_value', 14.689864354826563),\n",
       " ('exercised_stock_options', 13.714161147390753),\n",
       " ('salary', 11.196268305382173),\n",
       " ('bonus', 11.129479151071294),\n",
       " ('fraction_to_poi', 8.2430164382598381),\n",
       " ('restricted_stock', 6.5727016131222769),\n",
       " ('expenses', 5.8987344206928967),\n",
       " ('shared_receipt_with_poi', 5.495321379933408),\n",
       " ('deferred_income', 5.2791102364434765),\n",
       " ('total_payments', 2.7716344531988995),\n",
       " ('long_term_incentive', 2.611274332028505),\n",
       " ('fraction_from_poi', 2.3493376092169673),\n",
       " ('director_fees', 1.9616084482924003),\n",
       " ('restricted_stock_deferred', 0.79383448019177838),\n",
       " ('deferral_payments', 0.26396796392070854),\n",
       " ('loan_advances', 0.19714881780250351),\n",
       " ('other', 0.014163413206360534)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "sorted(feature_importance, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifiers to be explored**\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"K Nearest Neighbors\", \"RBF SVM\", \"Linear SVM\", \"Decision Tree\", \"Naive Bayes\", \n",
    "         \"AdaBoost\", \"Random Forest\", \"Logistic Regression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(), SVC(kernel='rbf', random_state=42), \\\n",
    "                SVC(kernel=\"linear\", random_state=42), DecisionTreeClassifier(random_state=42), \\\n",
    "                GaussianNB(), AdaBoostClassifier(random_state=42), RandomForestClassifier(random_state=42), \\\n",
    "                LogisticRegression(random_state=42)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iteration over various classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alonavarshal/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "confusion_matrices = []\n",
    "precisionscores = []\n",
    "recallscores = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(features_train_minmax_skb, labels_train)\n",
    "    score =  round(clf.score(features_test_minmax_skb, labels_test), 3)\n",
    "    test_scores.append(score)\n",
    "    pred = clf.predict(features_test_minmax_skb)\n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    confusion_matrices.append(conf_mat)\n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    precisionscores.append(precisionscore)\n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    recallscores.append(recallscore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling: SelectKBest\n",
      "Test Scores, Precision Scores, Recall Scores:\n",
      "[('Nearest Neighbors', 0.867, 0.0, 0.0),\n",
      " ('RBF SVM', 0.867, 0.0, 0.0),\n",
      " ('Linear SVM', 0.867, 0.0, 0.0),\n",
      " ('Decision Tree', 0.733, 0.25, 0.5),\n",
      " ('Naive Bayes', 0.867, 0.5, 1.0),\n",
      " ('AdaBoost', 0.933, 0.667, 1.0),\n",
      " ('Random Forest', 0.933, 1.0, 0.5),\n",
      " ('Logistic Regression', 0.933, 1.0, 0.5)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print \"Feature Scaling: SelectKBest\"\n",
    "print \"Test Scores, Precision Scores, Recall Scores:\"\n",
    "pprint.pprint(zip(names, test_scores, precisionscores, recallscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrices: \n",
      "[('Nearest Neighbors', array([[13,  0],\n",
      "       [ 2,  0]])),\n",
      " ('RBF SVM', array([[13,  0],\n",
      "       [ 2,  0]])),\n",
      " ('Linear SVM', array([[13,  0],\n",
      "       [ 2,  0]])),\n",
      " ('Decision Tree', array([[10,  3],\n",
      "       [ 1,  1]])),\n",
      " ('Naive Bayes', array([[11,  2],\n",
      "       [ 0,  2]])),\n",
      " ('AdaBoost', array([[12,  1],\n",
      "       [ 0,  2]])),\n",
      " ('Random Forest', array([[13,  0],\n",
      "       [ 1,  1]])),\n",
      " ('Logistic Regression', array([[13,  0],\n",
      "       [ 1,  1]]))]\n"
     ]
    }
   ],
   "source": [
    "print \"Confusion matrices: \"\n",
    "pprint.pprint(zip(names, confusion_matrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling Using PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I needed to use pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scores_pca = []\n",
    "confusion_matrices_pca = []\n",
    "precisionscores_pca = []\n",
    "recallscores_pca = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"pca\", PCA(random_state=42)), (\"clf\", clf)])\n",
    "    pipe.fit(features_train, labels_train)\n",
    "\n",
    "    score =  round(pipe.score(features_test, labels_test), 3)\n",
    "    test_scores_pca.append(score)\n",
    "\n",
    "    pred = pipe.predict(features_test)\n",
    "    \n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    confusion_matrices_pca.append(conf_mat)\n",
    "    \n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    precisionscores_pca.append(precisionscore)\n",
    "    \n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    recallscores_pca.append(recallscore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling: PCA\n",
      "Test Scores, Precision Scores, Recall Scores:\n",
      "[('Nearest Neighbors', 0.933, 1.0, 0.5),\n",
      " ('RBF SVM', 0.867, 0.0, 0.0),\n",
      " ('Linear SVM', 0.867, 0.0, 0.0),\n",
      " ('Decision Tree', 0.733, 0.25, 0.5),\n",
      " ('Naive Bayes', 0.867, 0.5, 1.0),\n",
      " ('AdaBoost', 0.867, 0.5, 0.5),\n",
      " ('Random Forest', 0.8, 0.0, 0.0),\n",
      " ('Logistic Regression', 0.867, 0.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print \"Feature Scaling: PCA\"\n",
    "print \"Test Scores, Precision Scores, Recall Scores:\"\n",
    "pprint.pprint(zip(names, test_scores_pca, precisionscores_pca, recallscores_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Testing whether my code above for SelectKBest is consistent with using Pipeline:**\n",
    "\n",
    "I tried repeating the selectkbest analysis above but using pipeline and see if this give me the same results as above. It's a good test whether I am doing things correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_scores_skb = []\n",
    "confusion_matrices_skb = []\n",
    "precisionscores_skb = []\n",
    "recallscores_skb = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe_skb = Pipeline([(\"scaler\", MinMaxScaler()), (\"skb\", SelectKBest()), (\"clf\", clf)])\n",
    "    pipe_skb.fit(features_train, labels_train)\n",
    "\n",
    "    score =  round(pipe_skb.score(features_test, labels_test), 3)\n",
    "    test_scores_skb.append(score)\n",
    "    \n",
    "    pred = pipe_skb.predict(features_test)\n",
    "\n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    confusion_matrices_skb.append(conf_mat)\n",
    "    \n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    precisionscores_skb.append(precisionscore)\n",
    "    \n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    recallscores_skb.append(recallscore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scaling: SelectKBest\n",
      "Test Scores, Precision Scores, Recall Scores:\n",
      "[('Nearest Neighbors', 0.867, 0.0, 0.0),\n",
      " ('RBF SVM', 0.867, 0.0, 0.0),\n",
      " ('Linear SVM', 0.867, 0.0, 0.0),\n",
      " ('Decision Tree', 0.733, 0.25, 0.5),\n",
      " ('Naive Bayes', 0.867, 0.5, 1.0),\n",
      " ('AdaBoost', 0.933, 0.667, 1.0),\n",
      " ('Random Forest', 0.933, 1.0, 0.5),\n",
      " ('Logistic Regression', 0.933, 1.0, 0.5)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "print \"Feature Scaling: SelectKBest\"\n",
    "print \"Test Scores, Precision Scores, Recall Scores:\"\n",
    "pprint.pprint(zip(names, test_scores_skb, precisionscores_skb, recallscores_skb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are the same. \n",
    "\n",
    "Below, I attempt to create dictionaries of results instead so I can convert them into pandas dataframes which are easier to look at than the lists above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"pca\", PCA(random_state=42)), (\"clf\", clf)])\n",
    "    pipe.fit(features_train, labels_train)\n",
    "    \n",
    "    pca_scores = {}\n",
    "\n",
    "    score =  round(pipe.score(features_test, labels_test), 3)\n",
    "    pca_scores[\"Accuracy score\"] = score\n",
    "\n",
    "    pred = pipe.predict(features_test)\n",
    "    \n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    pca_scores[\"Confusion matrix\"] = conf_mat\n",
    "    \n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    pca_scores[\"Precision score\"] = precisionscore\n",
    "    \n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    pca_scores[\"Recall score\"] = recallscore\n",
    "    \n",
    "    pca[name] = pca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaBoost': {'Accuracy score': 0.867,\n",
      "              'Confusion matrix': array([[12,  1],\n",
      "       [ 1,  1]]),\n",
      "              'Precision score': 0.5,\n",
      "              'Recall score': 0.5},\n",
      " 'Decision Tree': {'Accuracy score': 0.733,\n",
      "                   'Confusion matrix': array([[10,  3],\n",
      "       [ 1,  1]]),\n",
      "                   'Precision score': 0.25,\n",
      "                   'Recall score': 0.5},\n",
      " 'K Nearest Neighbors': {'Accuracy score': 0.933,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 1,  1]]),\n",
      "                         'Precision score': 1.0,\n",
      "                         'Recall score': 0.5},\n",
      " 'Linear SVM': {'Accuracy score': 0.867,\n",
      "                'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "                'Precision score': 0.0,\n",
      "                'Recall score': 0.0},\n",
      " 'Logistic Regression': {'Accuracy score': 0.867,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "                         'Precision score': 0.0,\n",
      "                         'Recall score': 0.0},\n",
      " 'Naive Bayes': {'Accuracy score': 0.867,\n",
      "                 'Confusion matrix': array([[11,  2],\n",
      "       [ 0,  2]]),\n",
      "                 'Precision score': 0.5,\n",
      "                 'Recall score': 1.0},\n",
      " 'RBF SVM': {'Accuracy score': 0.867,\n",
      "             'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "             'Precision score': 0.0,\n",
      "             'Recall score': 0.0},\n",
      " 'Random Forest': {'Accuracy score': 0.8,\n",
      "                   'Confusion matrix': array([[12,  1],\n",
      "       [ 2,  0]]),\n",
      "                   'Precision score': 0.0,\n",
      "                   'Recall score': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectkbest = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe_skb = Pipeline([(\"scaler\", MinMaxScaler()), (\"skb\", SelectKBest()), (\"clf\", clf)])\n",
    "    pipe_skb.fit(features_train, labels_train)\n",
    "    \n",
    "    skb_scores = {}\n",
    "\n",
    "    score =  round(pipe_skb.score(features_test, labels_test), 3)\n",
    "    skb_scores[\"Accuracy score\"] = score\n",
    "    \n",
    "    pred = pipe_skb.predict(features_test)\n",
    "\n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    skb_scores[\"Confusion matrix\"] = conf_mat\n",
    "    \n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    skb_scores[\"Precision score\"] = precisionscore\n",
    "    \n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    skb_scores[\"Recall score\"] = recallscore\n",
    "    \n",
    "    selectkbest[name] = skb_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaBoost': {'Accuracy score': 0.933,\n",
      "              'Confusion matrix': array([[12,  1],\n",
      "       [ 0,  2]]),\n",
      "              'Precision score': 0.667,\n",
      "              'Recall score': 1.0},\n",
      " 'Decision Tree': {'Accuracy score': 0.733,\n",
      "                   'Confusion matrix': array([[10,  3],\n",
      "       [ 1,  1]]),\n",
      "                   'Precision score': 0.25,\n",
      "                   'Recall score': 0.5},\n",
      " 'K Nearest Neighbors': {'Accuracy score': 0.867,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "                         'Precision score': 0.0,\n",
      "                         'Recall score': 0.0},\n",
      " 'Linear SVM': {'Accuracy score': 0.867,\n",
      "                'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "                'Precision score': 0.0,\n",
      "                'Recall score': 0.0},\n",
      " 'Logistic Regression': {'Accuracy score': 0.933,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 1,  1]]),\n",
      "                         'Precision score': 1.0,\n",
      "                         'Recall score': 0.5},\n",
      " 'Naive Bayes': {'Accuracy score': 0.867,\n",
      "                 'Confusion matrix': array([[11,  2],\n",
      "       [ 0,  2]]),\n",
      "                 'Precision score': 0.5,\n",
      "                 'Recall score': 1.0},\n",
      " 'RBF SVM': {'Accuracy score': 0.867,\n",
      "             'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "             'Precision score': 0.0,\n",
      "             'Recall score': 0.0},\n",
      " 'Random Forest': {'Accuracy score': 0.933,\n",
      "                   'Confusion matrix': array([[13,  0],\n",
      "       [ 1,  1]]),\n",
      "                   'Precision score': 1.0,\n",
      "                   'Recall score': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(selectkbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the dictionaries to pandas dataframe to easily see the scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>K Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy score</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion matrix</th>\n",
       "      <td>[[12, 1], [0, 2]]</td>\n",
       "      <td>[[10, 3], [1, 1]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[13, 0], [1, 1]]</td>\n",
       "      <td>[[11, 2], [0, 2]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[13, 0], [1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision score</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AdaBoost      Decision Tree K Nearest Neighbors  \\\n",
       "Accuracy score                0.933              0.733               0.867   \n",
       "Confusion matrix  [[12, 1], [0, 2]]  [[10, 3], [1, 1]]   [[13, 0], [2, 0]]   \n",
       "Precision score               0.667               0.25                   0   \n",
       "Recall score                      1                0.5                   0   \n",
       "\n",
       "                         Linear SVM Logistic Regression        Naive Bayes  \\\n",
       "Accuracy score                0.867               0.933              0.867   \n",
       "Confusion matrix  [[13, 0], [2, 0]]   [[13, 0], [1, 1]]  [[11, 2], [0, 2]]   \n",
       "Precision score                   0                   1                0.5   \n",
       "Recall score                      0                 0.5                  1   \n",
       "\n",
       "                            RBF SVM      Random Forest  \n",
       "Accuracy score                0.867              0.933  \n",
       "Confusion matrix  [[13, 0], [2, 0]]  [[13, 0], [1, 1]]  \n",
       "Precision score                   0                  1  \n",
       "Recall score                      0                0.5  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(selectkbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>K Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy score</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion matrix</th>\n",
       "      <td>[[12, 1], [1, 1]]</td>\n",
       "      <td>[[10, 3], [1, 1]]</td>\n",
       "      <td>[[13, 0], [1, 1]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[11, 2], [0, 2]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[12, 1], [2, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision score</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall score</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AdaBoost      Decision Tree K Nearest Neighbors  \\\n",
       "Accuracy score                0.867              0.733               0.933   \n",
       "Confusion matrix  [[12, 1], [1, 1]]  [[10, 3], [1, 1]]   [[13, 0], [1, 1]]   \n",
       "Precision score                 0.5               0.25                   1   \n",
       "Recall score                    0.5                0.5                 0.5   \n",
       "\n",
       "                         Linear SVM Logistic Regression        Naive Bayes  \\\n",
       "Accuracy score                0.867               0.867              0.867   \n",
       "Confusion matrix  [[13, 0], [2, 0]]   [[13, 0], [2, 0]]  [[11, 2], [0, 2]]   \n",
       "Precision score                   0                   0                0.5   \n",
       "Recall score                      0                   0                  1   \n",
       "\n",
       "                            RBF SVM      Random Forest  \n",
       "Accuracy score                0.867                0.8  \n",
       "Confusion matrix  [[13, 0], [2, 0]]  [[12, 1], [2, 0]]  \n",
       "Precision score                   0                  0  \n",
       "Recall score                      0                  0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the results above, the best classifiers are:\n",
    "\n",
    "SelectKBest feature selection:\n",
    "- AdaBoost\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "\n",
    "PCA as feature selection:\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "- AdaBoost\n",
    "\n",
    "Decision Tree can be used, probably need to optimize parameters. \n",
    "\n",
    "Next step is to optimize parameters. I chose to use the console for this as it is faster to run the poi_id.py and tester.py files and obtain results this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
