{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the best classifier for the POI in the Enron case using FeatureUnion (PCA and SelectKBest)\n",
    "\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Loading the data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features and number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      "['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n",
      "Number of features: 21\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "c = 0\n",
    "for key in data_dict:\n",
    "    if c < 1:\n",
    "        for feature in data_dict[key]:\n",
    "            all_features.append(feature)\n",
    "        c += 1\n",
    "print \"Features: \\n{}\".format(all_features)\n",
    "print \"Number of features: {}\".format(len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of poi == 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "poi = 0\n",
    "for key in data_dict:\n",
    "    if data_dict[key]['poi'] == 1:\n",
    "        poi += 1\n",
    "print poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of non-poi (poi == 0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict) - poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Removal of \"TOTAL\" and \"THE TRAVEL AGENCY IN THE PARK\"**\n",
    "\n",
    "\"TOTAL\"'s removal was discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop(\"TOTAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed from looking at the dictionary that \"THE TRAVEL AGENCY IN THE PARK\" isn't a person so I remove it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing what other people has done to treat data on the Enron case, I found out that LOCKHART EUGENE E does not have data in it, so it is removed here, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 'NaN',\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 'NaN',\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop('LOCKHART EUGENE E') # no data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fixing some data points**\n",
    "\n",
    "Also from other people's work, I found out that two datapoints have errors. Here, I manually fix the data for two people whose total_payments and total_stock_value didn't add up. These values were obtained from the pdf file provided (enron61702insiderpay.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict['BELFER ROBERT']['director_fees'] = 102500\n",
    "data_dict['BELFER ROBERT']['exercised_stock_options'] = 0\n",
    "data_dict['BELFER ROBERT']['expenses'] = 3285\n",
    "data_dict['BELFER ROBERT']['restricted_stock_deferred'] = -44093\n",
    "data_dict['BELFER ROBERT']['total_payments'] = 3285\n",
    "data_dict['BELFER ROBERT']['deferred_income'] = -102500\n",
    "data_dict['BELFER ROBERT']['deferral_payments'] = 0\n",
    "data_dict['BELFER ROBERT']['restricted_stock'] = 44093\n",
    "data_dict['BELFER ROBERT']['total_stock_value'] = 0\n",
    "\n",
    "data_dict['BHATNAGAR SANJAY']['director_fees'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['exercised_stock_options'] = 15456290\n",
    "data_dict['BHATNAGAR SANJAY']['expenses'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['other'] = 0\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock'] = 2604490\n",
    "data_dict['BHATNAGAR SANJAY']['restricted_stock_deferred'] = -2604490\n",
    "data_dict['BHATNAGAR SANJAY']['total_payments'] = 137864\n",
    "data_dict['BHATNAGAR SANJAY']['total_stock_value'] = 15456290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivation of new features, \"fraction_to_poi\", \"fraction_from_poi\"**\n",
    "\n",
    "These were discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeFraction(poi_messages, all_messages):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "    \"\"\"\n",
    "    if poi_messages != 'NaN' or all_messages != 'NaN':\n",
    "        fraction = float(poi_messages) / float(all_messages)\n",
    "    else:\n",
    "        fraction = 0\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in data_dict:\n",
    "    data_point = data_dict[name]\n",
    "    \n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction(from_poi_to_this_person, to_messages)\n",
    "    \n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "    \n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    \n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking whether the new features were added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "c = 0\n",
    "for key in data_dict:\n",
    "    if c < 1:\n",
    "        for feature in data_dict[key]:\n",
    "            all_features.append(feature)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to_messages',\n",
       " 'deferral_payments',\n",
       " 'expenses',\n",
       " 'poi',\n",
       " 'deferred_income',\n",
       " 'email_address',\n",
       " 'long_term_incentive',\n",
       " 'fraction_from_poi',\n",
       " 'restricted_stock_deferred',\n",
       " 'shared_receipt_with_poi',\n",
       " 'loan_advances',\n",
       " 'from_messages',\n",
       " 'other',\n",
       " 'director_fees',\n",
       " 'bonus',\n",
       " 'total_stock_value',\n",
       " 'from_poi_to_this_person',\n",
       " 'from_this_person_to_poi',\n",
       " 'restricted_stock',\n",
       " 'salary',\n",
       " 'total_payments',\n",
       " 'fraction_to_poi',\n",
       " 'exercised_stock_options']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removal of Some Features**\n",
    "\n",
    "Because of the new feautures above, it only makes sense to remove the features used to come up with the new features. \"email_address\" is removed because it will not give a numeric data type that can be used to create the numpy arrays for the analysis. \"poi\" is removed for the moment because it needs to be the first element in the list as indicated in the function used to create the numpy arrays (featureFormat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_remove = [\"poi\", \"email_address\", \"from_poi_to_this_person\", \"from_this_person_to_poi\", \"from_messages\", \"to_messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_list = ['poi', 'deferral_payments', 'expenses', 'deferred_income', 'long_term_incentive', 'fraction_from_poi', 'restricted_stock_deferred', 'shared_receipt_with_poi', 'loan_advances', 'other', 'director_fees', 'bonus', 'total_stock_value', 'restricted_stock', 'salary', 'total_payments', 'fraction_to_poi', 'exercised_stock_options']\n"
     ]
    }
   ],
   "source": [
    "features_list = [\"poi\"]\n",
    "for feature in all_features:\n",
    "    if feature not in features_remove:\n",
    "        features_list.append(feature)\n",
    "print \"features_list = {}\".format(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting features and labels from dataset for local testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring a variety of classifiers\n",
    "\n",
    "Here, I explore various classifiers by looping over them and collecting scores for each classfier in a dictionary.\n",
    "\n",
    "But before this can be done, the data is split into training and testing sets. As hinted in the provided tester.py, splitting the data is done using StratifiedShuffleSplit to account for the fact that the number of one class (i.e. POI) is a lot lower than the other (non-POI). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the features to test and train, converting to numpy arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "cv = StratifiedShuffleSplit(n_splits=1000, random_state=42)\n",
    "for train_idx, test_idx in cv.split(features, labels):\n",
    "    features_train, features_test = features[train_idx], features[test_idx]\n",
    "    labels_train, labels_test = labels[train_idx], labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importing modules **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifiers to be explored**\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"K Nearest Neighbors\", \"RBF SVM\", \"Linear SVM\", \"Decision Tree\", \"Naive Bayes\", \n",
    "         \"AdaBoost\", \"Random Forest\", \"Logistic Regression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(), SVC(kernel='rbf', random_state=42), \\\n",
    "                SVC(kernel=\"linear\", random_state=42), DecisionTreeClassifier(random_state=42), \\\n",
    "                GaussianNB(), AdaBoostClassifier(random_state=42), RandomForestClassifier(random_state=42), \\\n",
    "                LogisticRegression(random_state=42)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using FeatureUnion**\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/feature_stacker.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selection = SelectKBest(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use combined features to transform dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train_transformed = combined_features.fit(features_train, labels_train).transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_test_transformed = combined_features.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterating over numerous classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "    pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"features\", combined_features), (\"clf\", clf)])\n",
    "    pipe.fit(features_train, labels_train)\n",
    "    \n",
    "    scores = {}\n",
    "\n",
    "    score =  round(pipe.score(features_test, labels_test), 3)\n",
    "    scores[\"Accuracy score\"] = score\n",
    "\n",
    "    pred = pipe.predict(features_test)\n",
    "    \n",
    "    conf_mat = confusion_matrix(labels_test, pred)\n",
    "    scores[\"Confusion matrix\"] = conf_mat\n",
    "    \n",
    "    precisionscore = round(precision_score(labels_test, pred), 3)\n",
    "    scores[\"Precision score\"] = precisionscore\n",
    "    \n",
    "    recallscore = round(recall_score(labels_test, pred), 3)\n",
    "    scores[\"Recall score\"] = recallscore\n",
    "    \n",
    "    results[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaBoost': {'Accuracy score': 0.667,\n",
      "              'Confusion matrix': array([[10,  3],\n",
      "       [ 2,  0]]),\n",
      "              'Precision score': 0.0,\n",
      "              'Recall score': 0.0},\n",
      " 'Decision Tree': {'Accuracy score': 0.8,\n",
      "                   'Confusion matrix': array([[12,  1],\n",
      "       [ 2,  0]]),\n",
      "                   'Precision score': 0.0,\n",
      "                   'Recall score': 0.0},\n",
      " 'K Nearest Neighbors': {'Accuracy score': 0.933,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 1,  1]]),\n",
      "                         'Precision score': 1.0,\n",
      "                         'Recall score': 0.5},\n",
      " 'Linear SVM': {'Accuracy score': 0.867,\n",
      "                'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "                'Precision score': 0.0,\n",
      "                'Recall score': 0.0},\n",
      " 'Logistic Regression': {'Accuracy score': 0.933,\n",
      "                         'Confusion matrix': array([[13,  0],\n",
      "       [ 1,  1]]),\n",
      "                         'Precision score': 1.0,\n",
      "                         'Recall score': 0.5},\n",
      " 'Naive Bayes': {'Accuracy score': 0.8,\n",
      "                 'Confusion matrix': array([[11,  2],\n",
      "       [ 1,  1]]),\n",
      "                 'Precision score': 0.333,\n",
      "                 'Recall score': 0.5},\n",
      " 'RBF SVM': {'Accuracy score': 0.867,\n",
      "             'Confusion matrix': array([[13,  0],\n",
      "       [ 2,  0]]),\n",
      "             'Precision score': 0.0,\n",
      "             'Recall score': 0.0},\n",
      " 'Random Forest': {'Accuracy score': 0.733,\n",
      "                   'Confusion matrix': array([[10,  3],\n",
      "       [ 1,  1]]),\n",
      "                   'Precision score': 0.25,\n",
      "                   'Recall score': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting the dictionaries to pandas dataframe to easily see the scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>K Nearest Neighbors</th>\n",
       "      <th>Linear SVM</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>RBF SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy score</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion matrix</th>\n",
       "      <td>[[10, 3], [2, 0]]</td>\n",
       "      <td>[[12, 1], [2, 0]]</td>\n",
       "      <td>[[13, 0], [1, 1]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[13, 0], [1, 1]]</td>\n",
       "      <td>[[11, 2], [1, 1]]</td>\n",
       "      <td>[[13, 0], [2, 0]]</td>\n",
       "      <td>[[10, 3], [1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AdaBoost      Decision Tree K Nearest Neighbors  \\\n",
       "Accuracy score                0.667                0.8               0.933   \n",
       "Confusion matrix  [[10, 3], [2, 0]]  [[12, 1], [2, 0]]   [[13, 0], [1, 1]]   \n",
       "Precision score                   0                  0                   1   \n",
       "Recall score                      0                  0                 0.5   \n",
       "\n",
       "                         Linear SVM Logistic Regression        Naive Bayes  \\\n",
       "Accuracy score                0.867               0.933                0.8   \n",
       "Confusion matrix  [[13, 0], [2, 0]]   [[13, 0], [1, 1]]  [[11, 2], [1, 1]]   \n",
       "Precision score                   0                   1              0.333   \n",
       "Recall score                      0                 0.5                0.5   \n",
       "\n",
       "                            RBF SVM      Random Forest  \n",
       "Accuracy score                0.867              0.733  \n",
       "Confusion matrix  [[13, 0], [2, 0]]  [[10, 3], [1, 1]]  \n",
       "Precision score                   0               0.25  \n",
       "Recall score                      0                0.5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Best ones:\n",
    "\n",
    "- KNN\n",
    "- Logistic Regressino\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "\n",
    "\n",
    "See poi_id_skb_pca_featureunion_knn.py for optimizing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
